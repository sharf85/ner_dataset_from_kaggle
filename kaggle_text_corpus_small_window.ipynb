{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotated Corpus for Named Entity Recognition (From Kaggle)\n",
    "In this notebook we're building a basic model for NER on the specified corpus using splitting all the sentences down to shorter sequences of words of a fixed length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data\n",
    "Downloading the data - it is already well preprocessed - there are a lot of features added to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 281837: expected 25 fields, saw 34\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lemma</th>\n",
       "      <th>next-lemma</th>\n",
       "      <th>next-next-lemma</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-shape</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-shape</th>\n",
       "      <th>next-word</th>\n",
       "      <th>...</th>\n",
       "      <th>prev-prev-lemma</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-shape</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-shape</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>shape</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281835</th>\n",
       "      <td>0</td>\n",
       "      <td>thousand</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>...</td>\n",
       "      <td>__start2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281836</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>...</td>\n",
       "      <td>__start1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>wildcard</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281837</th>\n",
       "      <td>2</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>...</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NNS</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281838</th>\n",
       "      <td>3</td>\n",
       "      <td>have</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>...</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>of</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281839</th>\n",
       "      <td>4</td>\n",
       "      <td>march</td>\n",
       "      <td>through</td>\n",
       "      <td>london</td>\n",
       "      <td>NNP</td>\n",
       "      <td>capitalized</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>through</td>\n",
       "      <td>...</td>\n",
       "      <td>demonstr</td>\n",
       "      <td>NNS</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lowercase</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0     lemma next-lemma next-next-lemma next-next-pos  \\\n",
       "281835           0  thousand         of        demonstr           NNS   \n",
       "281836           1        of   demonstr            have           VBP   \n",
       "281837           2  demonstr       have           march           VBN   \n",
       "281838           3      have      march         through            IN   \n",
       "281839           4     march    through          london           NNP   \n",
       "\n",
       "       next-next-shape next-next-word next-pos next-shape      next-word ...  \\\n",
       "281835       lowercase  demonstrators       IN  lowercase             of ...   \n",
       "281836       lowercase           have      NNS  lowercase  demonstrators ...   \n",
       "281837       lowercase        marched      VBP  lowercase           have ...   \n",
       "281838       lowercase        through      VBN  lowercase        marched ...   \n",
       "281839     capitalized         London       IN  lowercase        through ...   \n",
       "\n",
       "       prev-prev-lemma prev-prev-pos prev-prev-shape prev-prev-word  \\\n",
       "281835      __start2__    __START2__        wildcard     __START2__   \n",
       "281836      __start1__    __START1__        wildcard     __START1__   \n",
       "281837        thousand           NNS     capitalized      Thousands   \n",
       "281838              of            IN       lowercase             of   \n",
       "281839        demonstr           NNS       lowercase  demonstrators   \n",
       "\n",
       "         prev-shape      prev-word sentence_idx        shape           word  \\\n",
       "281835     wildcard     __START1__          1.0  capitalized      Thousands   \n",
       "281836  capitalized      Thousands          1.0    lowercase             of   \n",
       "281837    lowercase             of          1.0    lowercase  demonstrators   \n",
       "281838    lowercase  demonstrators          1.0    lowercase           have   \n",
       "281839    lowercase           have          1.0    lowercase        marched   \n",
       "\n",
       "       tag  \n",
       "281835   O  \n",
       "281836   O  \n",
       "281837   O  \n",
       "281838   O  \n",
       "281839   O  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/ner.csv\", encoding = \"ISO-8859-1\", error_bad_lines=False)\n",
    "df = df.iloc[281835:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to leave only the initial text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>281835</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281836</th>\n",
       "      <td>1.0</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281837</th>\n",
       "      <td>1.0</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281838</th>\n",
       "      <td>1.0</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281839</th>\n",
       "      <td>1.0</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_idx           word tag\n",
       "281835           1.0      Thousands   O\n",
       "281836           1.0             of   O\n",
       "281837           1.0  demonstrators   O\n",
       "281838           1.0           have   O\n",
       "281839           1.0        marched   O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=df.drop(['Unnamed: 0', 'lemma', 'next-lemma', 'next-next-lemma', 'next-next-pos',\n",
    "       'next-next-shape', 'next-next-word', 'next-pos', 'next-shape',\n",
    "       'next-word', 'prev-iob', 'prev-lemma', 'prev-pos',\n",
    "       'prev-prev-iob', 'prev-prev-lemma', 'prev-prev-pos', 'prev-prev-shape',\n",
    "       'prev-prev-word', 'prev-shape', 'prev-word',\"pos\",\"shape\"],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data into list of sentencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from text_preprocessing import group_sentences, tokenize, pad, split_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forming text sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence: Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
      "Sample label sentence: O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n"
     ]
    }
   ],
   "source": [
    "input_sentences, label_sentences = group_sentences(data, \"word\"), group_sentences(data, \"tag\")\n",
    "print(\"Sample sentence:\", input_sentences[0])\n",
    "print(\"Sample label sentence:\", label_sentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 27420\n",
      "Vocabulary size: 18\n"
     ]
    }
   ],
   "source": [
    "tokenized_input, tokenizer_X = tokenize(input_sentences)\n",
    "tokenized_labels, tokenizer_y = tokenize(label_sentences, to_lower=False)\n",
    "\n",
    "input_vocab_size = len(tokenizer_X.word_index) + 1\n",
    "labels_vocab_size = len(tokenizer_y.word_index) + 1\n",
    "\n",
    "print(\"Vocabulary size:\", input_vocab_size)\n",
    "print(\"Vocabulary size:\", labels_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing sentences to the fixed length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 8\n",
    "\n",
    "divided_tokenized_input = split_sentences(tokenized_input, WINDOW_SIZE)\n",
    "divided_tokenized_labels = split_sentences(tokenized_labels, WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = divided_tokenized_labels.reshape(*divided_tokenized_labels.shape, 1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(divided_tokenized_input, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import embed_gru_model,embed_bi_gru_model,encdec_embed_gru_model\n",
    "from evaluation import Evaluator\n",
    "eval = Evaluator(tokenizer_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One directional GRU model\n",
    "![RNN](images/embedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:508: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3837: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:127: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3144: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/keras/optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3040: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 8, 128)            3509760   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 8, 128)            98688     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 8, 18)             2322      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8, 18)             0         \n",
      "=================================================================\n",
      "Total params: 3,610,770\n",
      "Trainable params: 3,610,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_gru_model = embed_gru_model(WINDOW_SIZE, input_vocab_size, labels_vocab_size)\n",
    "embed_gru_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/evgeny/anaconda3/envs/tensorflow_rnn/lib/python3.5/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 335349 samples, validate on 83838 samples\n",
      "Epoch 1/15\n",
      "335349/335349 [==============================] - 56s 167us/step - loss: 0.5400 - acc: 0.9020 - val_loss: 0.1874 - val_acc: 0.9517\n",
      "Epoch 2/15\n",
      "335349/335349 [==============================] - 58s 174us/step - loss: 0.1547 - acc: 0.9560 - val_loss: 0.1310 - val_acc: 0.9599\n",
      "Epoch 3/15\n",
      "335349/335349 [==============================] - 62s 184us/step - loss: 0.1233 - acc: 0.9612 - val_loss: 0.1146 - val_acc: 0.9633\n",
      "Epoch 4/15\n",
      "335349/335349 [==============================] - 62s 183us/step - loss: 0.1104 - acc: 0.9642 - val_loss: 0.1059 - val_acc: 0.9655\n",
      "Epoch 5/15\n",
      "335349/335349 [==============================] - 60s 180us/step - loss: 0.1026 - acc: 0.9661 - val_loss: 0.1006 - val_acc: 0.9670\n",
      "Epoch 6/15\n",
      "335349/335349 [==============================] - 62s 185us/step - loss: 0.0970 - acc: 0.9676 - val_loss: 0.0964 - val_acc: 0.9679\n",
      "Epoch 7/15\n",
      "335349/335349 [==============================] - 61s 182us/step - loss: 0.0925 - acc: 0.9689 - val_loss: 0.0926 - val_acc: 0.9693\n",
      "Epoch 8/15\n",
      "335349/335349 [==============================] - 61s 182us/step - loss: 0.0882 - acc: 0.9700 - val_loss: 0.0892 - val_acc: 0.9702\n",
      "Epoch 9/15\n",
      "335349/335349 [==============================] - 64s 190us/step - loss: 0.0846 - acc: 0.9712 - val_loss: 0.0862 - val_acc: 0.9712\n",
      "Epoch 10/15\n",
      "335349/335349 [==============================] - 63s 189us/step - loss: 0.0815 - acc: 0.9722 - val_loss: 0.0845 - val_acc: 0.9717\n",
      "Epoch 11/15\n",
      "335349/335349 [==============================] - 63s 187us/step - loss: 0.0782 - acc: 0.9732 - val_loss: 0.0816 - val_acc: 0.9729\n",
      "Epoch 12/15\n",
      "335349/335349 [==============================] - 63s 187us/step - loss: 0.0755 - acc: 0.9740 - val_loss: 0.0791 - val_acc: 0.9735\n",
      "Epoch 13/15\n",
      "335349/335349 [==============================] - 63s 187us/step - loss: 0.0732 - acc: 0.9747 - val_loss: 0.0778 - val_acc: 0.9739\n",
      "Epoch 14/15\n",
      "335349/335349 [==============================] - 62s 185us/step - loss: 0.0709 - acc: 0.9755 - val_loss: 0.0765 - val_acc: 0.9744\n",
      "Epoch 15/15\n",
      "335349/335349 [==============================] - 62s 185us/step - loss: 0.0690 - acc: 0.9762 - val_loss: 0.0749 - val_acc: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f078472e208>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_gru_model.fit(X_train, y_train, batch_size=1024, epochs=15, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "      nat       0.79      0.56      0.65       190\n",
      "      per       0.84      0.87      0.85     13462\n",
      "      gpe       0.96      0.96      0.96     11237\n",
      "      tim       0.89      0.86      0.88     16232\n",
      "      eve       0.55      0.48      0.51       273\n",
      "      org       0.65      0.65      0.65     16531\n",
      "      geo       0.86      0.93      0.89     29373\n",
      "      art       0.66      0.49      0.56       318\n",
      "\n",
      "micro avg       0.84      0.85      0.84     87616\n",
      "macro avg       0.83      0.85      0.84     87616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(eval.evaluate_metrics(y_test, embed_gru_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bi-directional GRU model\n",
    "![RNN](images/bidirectional.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 8, 128)            3509760   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 8, 256)            197376    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 8, 18)             4626      \n",
      "=================================================================\n",
      "Total params: 3,711,762\n",
      "Trainable params: 3,711,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_bi_gru_model = embed_bi_gru_model(WINDOW_SIZE, input_vocab_size, labels_vocab_size)\n",
    "embed_bi_gru_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 335349 samples, validate on 83838 samples\n",
      "Epoch 1/15\n",
      "335349/335349 [==============================] - 97s 288us/step - loss: 0.4742 - acc: 0.9038 - val_loss: 0.1560 - val_acc: 0.9563\n",
      "Epoch 2/15\n",
      "335349/335349 [==============================] - 101s 301us/step - loss: 0.1255 - acc: 0.9625 - val_loss: 0.1043 - val_acc: 0.9674\n",
      "Epoch 3/15\n",
      "335349/335349 [==============================] - 108s 322us/step - loss: 0.0951 - acc: 0.9694 - val_loss: 0.0875 - val_acc: 0.9716\n",
      "Epoch 4/15\n",
      "335349/335349 [==============================] - 107s 318us/step - loss: 0.0814 - acc: 0.9731 - val_loss: 0.0790 - val_acc: 0.9741\n",
      "Epoch 5/15\n",
      "335349/335349 [==============================] - 106s 317us/step - loss: 0.0721 - acc: 0.9760 - val_loss: 0.0724 - val_acc: 0.9760\n",
      "Epoch 6/15\n",
      "335349/335349 [==============================] - 107s 320us/step - loss: 0.0650 - acc: 0.9781 - val_loss: 0.0673 - val_acc: 0.9775\n",
      "Epoch 7/15\n",
      "335349/335349 [==============================] - 107s 319us/step - loss: 0.0593 - acc: 0.9799 - val_loss: 0.0638 - val_acc: 0.9786\n",
      "Epoch 8/15\n",
      "335349/335349 [==============================] - 107s 320us/step - loss: 0.0544 - acc: 0.9814 - val_loss: 0.0601 - val_acc: 0.9799\n",
      "Epoch 9/15\n",
      "335349/335349 [==============================] - 111s 331us/step - loss: 0.0503 - acc: 0.9827 - val_loss: 0.0572 - val_acc: 0.9808\n",
      "Epoch 10/15\n",
      "335349/335349 [==============================] - 113s 337us/step - loss: 0.0465 - acc: 0.9839 - val_loss: 0.0547 - val_acc: 0.9817\n",
      "Epoch 11/15\n",
      "335349/335349 [==============================] - 116s 347us/step - loss: 0.0434 - acc: 0.9851 - val_loss: 0.0528 - val_acc: 0.9823\n",
      "Epoch 12/15\n",
      "335349/335349 [==============================] - 112s 334us/step - loss: 0.0403 - acc: 0.9861 - val_loss: 0.0506 - val_acc: 0.9833\n",
      "Epoch 13/15\n",
      "335349/335349 [==============================] - 111s 330us/step - loss: 0.0376 - acc: 0.9870 - val_loss: 0.0489 - val_acc: 0.9839\n",
      "Epoch 14/15\n",
      "335349/335349 [==============================] - 111s 331us/step - loss: 0.0351 - acc: 0.9879 - val_loss: 0.0483 - val_acc: 0.9842\n",
      "Epoch 15/15\n",
      "335349/335349 [==============================] - 109s 324us/step - loss: 0.0330 - acc: 0.9885 - val_loss: 0.0470 - val_acc: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f077074d668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_bi_gru_model.fit(X_train, y_train, batch_size=1024, epochs=15, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "      nat       0.83      0.72      0.77       190\n",
      "      per       0.92      0.91      0.91     13462\n",
      "      gpe       0.98      0.96      0.97     11237\n",
      "      tim       0.93      0.92      0.93     16232\n",
      "      eve       0.70      0.74      0.72       273\n",
      "      org       0.84      0.83      0.83     16531\n",
      "      geo       0.93      0.95      0.94     29373\n",
      "      art       0.82      0.70      0.76       318\n",
      "\n",
      "micro avg       0.92      0.91      0.92     87616\n",
      "macro avg       0.92      0.91      0.92     87616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(eval.evaluate_metrics(y_test, embed_bi_gru_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bi-directional GRU encoder decoder model\n",
    "![RNN](images/encoder-decoder.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 8, 64)        1754880     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     [(None, 128), (None, 74112       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "encoder_dense (Dense)           (None, 128)          16512       gru_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           encoder_dense[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 1, 128)       0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     [(None, 1, 128), (No 98688       repeat_vector_1[0][0]            \n",
      "                                                                 gru_3[0][1]                      \n",
      "                                                                 gru_4[0][0]                      \n",
      "                                                                 gru_4[0][1]                      \n",
      "                                                                 gru_4[1][0]                      \n",
      "                                                                 gru_4[1][1]                      \n",
      "                                                                 gru_4[2][0]                      \n",
      "                                                                 gru_4[2][1]                      \n",
      "                                                                 gru_4[3][0]                      \n",
      "                                                                 gru_4[3][1]                      \n",
      "                                                                 gru_4[4][0]                      \n",
      "                                                                 gru_4[4][1]                      \n",
      "                                                                 gru_4[5][0]                      \n",
      "                                                                 gru_4[5][1]                      \n",
      "                                                                 gru_4[6][0]                      \n",
      "                                                                 gru_4[6][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_dense (Dense)           (None, 1, 18)        2322        gru_4[0][0]                      \n",
      "                                                                 gru_4[1][0]                      \n",
      "                                                                 gru_4[2][0]                      \n",
      "                                                                 gru_4[3][0]                      \n",
      "                                                                 gru_4[4][0]                      \n",
      "                                                                 gru_4[5][0]                      \n",
      "                                                                 gru_4[6][0]                      \n",
      "                                                                 gru_4[7][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 8, 18)        0           decoder_dense[0][0]              \n",
      "                                                                 decoder_dense[1][0]              \n",
      "                                                                 decoder_dense[2][0]              \n",
      "                                                                 decoder_dense[3][0]              \n",
      "                                                                 decoder_dense[4][0]              \n",
      "                                                                 decoder_dense[5][0]              \n",
      "                                                                 decoder_dense[6][0]              \n",
      "                                                                 decoder_dense[7][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,946,514\n",
      "Trainable params: 1,946,514\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encdec_embed_gru_model=encdec_embed_gru_model(WINDOW_SIZE, input_vocab_size, labels_vocab_size)\n",
    "encdec_embed_gru_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 335349 samples, validate on 83838 samples\n",
      "Epoch 1/30\n",
      "335349/335349 [==============================] - 100s 299us/step - loss: 0.7339 - acc: 0.8531 - val_loss: 0.5327 - val_acc: 0.8583\n",
      "Epoch 2/30\n",
      "335349/335349 [==============================] - 97s 288us/step - loss: 0.4505 - acc: 0.8735 - val_loss: 0.3505 - val_acc: 0.8979\n",
      "Epoch 3/30\n",
      "335349/335349 [==============================] - 100s 298us/step - loss: 0.3124 - acc: 0.9098 - val_loss: 0.2269 - val_acc: 0.9386\n",
      "Epoch 4/30\n",
      "335349/335349 [==============================] - 100s 297us/step - loss: 0.2192 - acc: 0.9382 - val_loss: 0.1694 - val_acc: 0.9540\n",
      "Epoch 5/30\n",
      "335349/335349 [==============================] - 95s 282us/step - loss: 0.1738 - acc: 0.9507 - val_loss: 0.1418 - val_acc: 0.9602\n",
      "Epoch 6/30\n",
      "335349/335349 [==============================] - 95s 282us/step - loss: 0.1482 - acc: 0.9573 - val_loss: 0.1266 - val_acc: 0.9638\n",
      "Epoch 7/30\n",
      "335349/335349 [==============================] - 95s 282us/step - loss: 0.1318 - acc: 0.9612 - val_loss: 0.1156 - val_acc: 0.9662\n",
      "Epoch 8/30\n",
      "335349/335349 [==============================] - 95s 282us/step - loss: 0.1198 - acc: 0.9644 - val_loss: 0.1081 - val_acc: 0.9681\n",
      "Epoch 9/30\n",
      "335349/335349 [==============================] - 96s 286us/step - loss: 0.1102 - acc: 0.9669 - val_loss: 0.1007 - val_acc: 0.9701\n",
      "Epoch 10/30\n",
      "335349/335349 [==============================] - 96s 285us/step - loss: 0.1025 - acc: 0.9690 - val_loss: 0.0958 - val_acc: 0.9714\n",
      "Epoch 11/30\n",
      "335349/335349 [==============================] - 97s 290us/step - loss: 0.0961 - acc: 0.9706 - val_loss: 0.0911 - val_acc: 0.9724\n",
      "Epoch 12/30\n",
      "335349/335349 [==============================] - 96s 287us/step - loss: 0.0902 - acc: 0.9723 - val_loss: 0.0880 - val_acc: 0.9734\n",
      "Epoch 13/30\n",
      "335349/335349 [==============================] - 105s 313us/step - loss: 0.0855 - acc: 0.9735 - val_loss: 0.0843 - val_acc: 0.9746\n",
      "Epoch 14/30\n",
      "335349/335349 [==============================] - 99s 294us/step - loss: 0.0813 - acc: 0.9748 - val_loss: 0.0818 - val_acc: 0.9752\n",
      "Epoch 15/30\n",
      "335349/335349 [==============================] - 96s 285us/step - loss: 0.0777 - acc: 0.9758 - val_loss: 0.0793 - val_acc: 0.9758\n",
      "Epoch 16/30\n",
      "335349/335349 [==============================] - 97s 289us/step - loss: 0.0739 - acc: 0.9769 - val_loss: 0.0773 - val_acc: 0.9763\n",
      "Epoch 17/30\n",
      "335349/335349 [==============================] - 96s 287us/step - loss: 0.0713 - acc: 0.9776 - val_loss: 0.0764 - val_acc: 0.9767\n",
      "Epoch 18/30\n",
      "335349/335349 [==============================] - 95s 284us/step - loss: 0.0684 - acc: 0.9785 - val_loss: 0.0741 - val_acc: 0.9773\n",
      "Epoch 19/30\n",
      "335349/335349 [==============================] - 95s 282us/step - loss: 0.0660 - acc: 0.9792 - val_loss: 0.0718 - val_acc: 0.9779\n",
      "Epoch 20/30\n",
      "335349/335349 [==============================] - 96s 285us/step - loss: 0.0635 - acc: 0.9798 - val_loss: 0.0715 - val_acc: 0.9781\n",
      "Epoch 21/30\n",
      "335349/335349 [==============================] - 94s 281us/step - loss: 0.0613 - acc: 0.9806 - val_loss: 0.0701 - val_acc: 0.9784\n",
      "Epoch 22/30\n",
      "335349/335349 [==============================] - 94s 281us/step - loss: 0.0595 - acc: 0.9810 - val_loss: 0.0691 - val_acc: 0.9788\n",
      "Epoch 23/30\n",
      "335349/335349 [==============================] - 95s 282us/step - loss: 0.0576 - acc: 0.9816 - val_loss: 0.0677 - val_acc: 0.9794\n",
      "Epoch 24/30\n",
      "335349/335349 [==============================] - 96s 287us/step - loss: 0.0561 - acc: 0.9821 - val_loss: 0.0675 - val_acc: 0.9794\n",
      "Epoch 25/30\n",
      "335349/335349 [==============================] - 96s 287us/step - loss: 0.0545 - acc: 0.9825 - val_loss: 0.0660 - val_acc: 0.9799\n",
      "Epoch 26/30\n",
      "335349/335349 [==============================] - 96s 287us/step - loss: 0.0531 - acc: 0.9829 - val_loss: 0.0655 - val_acc: 0.9801\n",
      "Epoch 27/30\n",
      "335349/335349 [==============================] - 96s 286us/step - loss: 0.0519 - acc: 0.9832 - val_loss: 0.0657 - val_acc: 0.9802\n",
      "Epoch 28/30\n",
      "335349/335349 [==============================] - 96s 286us/step - loss: 0.0508 - acc: 0.9836 - val_loss: 0.0640 - val_acc: 0.9806\n",
      "Epoch 29/30\n",
      "335349/335349 [==============================] - 97s 288us/step - loss: 0.0496 - acc: 0.9839 - val_loss: 0.0634 - val_acc: 0.9808\n",
      "Epoch 30/30\n",
      "335349/335349 [==============================] - 96s 286us/step - loss: 0.0484 - acc: 0.9842 - val_loss: 0.0634 - val_acc: 0.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f074857bb00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encdec_embed_gru_model.fit(X_train, y_train, batch_size=1024, epochs=30, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "      nat       0.86      0.66      0.75       190\n",
      "      per       0.88      0.89      0.88     13462\n",
      "      gpe       0.97      0.96      0.97     11237\n",
      "      tim       0.91      0.91      0.91     16232\n",
      "      eve       0.62      0.58      0.60       273\n",
      "      org       0.80      0.79      0.80     16531\n",
      "      geo       0.91      0.94      0.92     29373\n",
      "      art       0.78      0.58      0.66       318\n",
      "\n",
      "micro avg       0.89      0.90      0.89     87616\n",
      "macro avg       0.89      0.90      0.89     87616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(eval.evaluate_metrics(y_test, encdec_embed_gru_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
